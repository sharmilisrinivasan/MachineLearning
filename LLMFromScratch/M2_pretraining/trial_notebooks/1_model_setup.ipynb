{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize & Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sys path for imports to work\n",
    "import sys\n",
    "# print(f\"Before: {\"\\n\".join(sys.path)}\")  ## Optional print to check\n",
    "sys.path.append(\"../../../LLMFromScratch\")\n",
    "# print(f\"After: {\"\\n\".join(sys.path)}\")  ## Optional print to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from M0_data.helpers import GPT2Tokenizer, create_data_loader\n",
    "from M1_simple_gpt_model.generate import generate_text\n",
    "from M1_simple_gpt_model.trial_gpt_model import TrialGPTModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"context_length\": 256, # Context Length supported by the model; Using reduced size to reduce compute resources; Actual value: 1024\n",
    "    \"drop_rate\" : 0.1,  # Tring with smaller prob number, Can be kept zero.\n",
    "    \"emb_dim\": 768,  # Dimension of Embedding to be created\n",
    "    \"n_heads\": 12,  # Number of heads in Multi-Head Attention\n",
    "    \"n_layers\": 12,  # Number of times Transformer block is repeated\n",
    "    \"qvbias\": False,  # Skipping bias terms to make the transformers training faster\n",
    "    \"vocab_size\": 50257,  # Size of gpt2 tokenizer used\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)  # For consistent reproducibility\n",
    "model = TrialGPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrialGPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (linear_out): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval() # Switch to Evaluation mode - NOT Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Sample Test Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Inputs - of Different lengths\n",
    "in_strings = [\"Every effort moves you towards your goal\",\n",
    "              \"Every day holds a\",\n",
    "              \"This statement is going to have longest token length \"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer()\n",
    "tokenized_in_strings = tokenizer.tokenize_batch(in_strings)\n",
    "tokenized_in_strings.shape  # batch_size * in_seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Generate Output with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens = generate_text(model, tokenized_in_strings, 1, GPT_CONFIG_124M[\"context_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 11])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens.shape  # batch_size * min(in_seq_len, context_length)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Detokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Every effort moves you towards your goal inv',\n",
       " 'Every day holds a respec',\n",
       " 'This statement is going to have longest token length ï¿½']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tokenizer.detokenize_batch(output_tokens)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Trial data & Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20161\n",
      "The story revolves around Vandiyathevan, a charming, brave and courageous young man who sets out ac\n",
      "nd meet Manimegalai. Vandiyathevan goes to meet Manimegalai, who loved him, and dies in his hands.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../M0_data/ponniyinselvan.txt\", \"r\", encoding=\"utf-8\") as read_file:\n",
    "    raw_text = read_file.read()\n",
    "\n",
    "# Print length\n",
    "print(len(raw_text))\n",
    "\n",
    "# Print first 100 characters\n",
    "print(raw_text[:99])\n",
    "\n",
    "# Print last 100 characters\n",
    "print(raw_text[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5330])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_raw_text = tokenizer.tokenize_batch(raw_text)\n",
    "tokenized_raw_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train and Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Initialize config values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10907f1d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2  # Small as short training set; Actual Size in Llama2 7B: 1024\n",
    "train_ratio = 0.90  # 90% Train set\n",
    "torch.manual_seed(123)  # For consistent reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Actual Split to Train and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18144\n"
     ]
    }
   ],
   "source": [
    "split_idx = int(len(raw_text) * train_ratio)\n",
    "print(split_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Set\n",
    "train_set = raw_text[:split_idx]\n",
    "train_loader = create_data_loader(train_set,\n",
    "                                  max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "                                  stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,  # For training shuffling is ok\n",
    "                                  drop_last=True,\n",
    "                                  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Set\n",
    "validation_set = raw_text[split_idx:]\n",
    "validation_loader = create_data_loader(validation_set,\n",
    "                                       max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "                                       stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=False,  # For validation shuffling is turned off\n",
    "                                       drop_last=False,  # Need to infer on last short batch as well\n",
    "                                       num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to forward to next steps\n",
    "torch.save(train_loader, \"intermediates/train_loader.pt\")\n",
    "torch.save(validation_loader, \"intermediates/validation_loader.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Test Data loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# Train set\n",
    "train_tokens = 0\n",
    "for in_data, out_data in train_loader:\n",
    "    print(in_data.shape, out_data.shape)\n",
    "    train_tokens += in_data.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# Validation set\n",
    "validation_tokens = 0\n",
    "for in_data, out_data in validation_loader:\n",
    "    print(in_data.shape, out_data.shape)\n",
    "    validation_tokens += in_data.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Tokens: 4608\n",
      "Validation Tokens: 512\n",
      "Total Tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "# Token count verification\n",
    "print(f\"Train Tokens: {train_tokens}\")\n",
    "print(f\"Validation Tokens: {validation_tokens}\")\n",
    "print(f\"Total Tokens: {train_tokens + validation_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initial Loss before Training"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy Formula\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Notes: \n",
    "1. The input can be logits as it is normalised by dividing by sum across classes in formula above\n",
    "2. When Batch is provided i.e. Tensor [Batch, Classes], by default output loss is mean across batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, device, model):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    logits, target_batch = logits.flatten(0, 1), target_batch.flatten()  # flatten(start, end) Flattens dimensions from start to end idx specified\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "def calc_loss_multi_batch(data_loader, device, model):\n",
    "    num_batches = len(data_loader)\n",
    "\n",
    "    if num_batches == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    total_loss = 0.\n",
    "    for input_batch, target_batch in data_loader:\n",
    "        total_loss += calc_loss_batch(input_batch, target_batch, device, model)\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrialGPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (norm_1): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (linear_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (linear_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (drop_out): Dropout(p=0.1, inplace=False)\n",
       "      (norm_2): LayerNorm()\n",
       "      (feed_forward): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (linear_out): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10907f1d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_multi_batch(train_loader, device, model)\n",
    "    val_loss = calc_loss_multi_batch(validation_loader, device, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10.96826457977295\n",
      "Validation Loss: 10.963376998901367\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Loss: {train_loss}\")\n",
    "print(f\"Validation Loss: {val_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_from_scratch_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
