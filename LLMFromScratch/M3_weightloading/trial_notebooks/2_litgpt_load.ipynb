{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install litgpt[all] >= 0.4.1\n",
    "# pip install -v \"lightning<2.5.0.post0\" # To avoid a ArgumentParser error during litgt download list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supported LLMs check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify --repo_id <repo_id>. Available values:\n",
      "allenai/OLMo-1B-hf\n",
      "allenai/OLMo-7B-hf\n",
      "allenai/OLMo-7B-Instruct-hf\n",
      "BSC-LT/salamandra-2b\n",
      "BSC-LT/salamandra-2b-instruct\n",
      "BSC-LT/salamandra-7b\n",
      "BSC-LT/salamandra-7b-instruct\n",
      "codellama/CodeLlama-13b-hf\n",
      "codellama/CodeLlama-13b-Instruct-hf\n",
      "codellama/CodeLlama-13b-Python-hf\n",
      "codellama/CodeLlama-34b-hf\n",
      "codellama/CodeLlama-34b-Instruct-hf\n",
      "codellama/CodeLlama-34b-Python-hf\n",
      "codellama/CodeLlama-70b-hf\n",
      "codellama/CodeLlama-70b-Instruct-hf\n",
      "codellama/CodeLlama-70b-Python-hf\n",
      "codellama/CodeLlama-7b-hf\n",
      "codellama/CodeLlama-7b-Instruct-hf\n",
      "codellama/CodeLlama-7b-Python-hf\n",
      "deepseek-ai/DeepSeek-R1-Distill-Llama-70B\n",
      "deepseek-ai/DeepSeek-R1-Distill-Llama-8B\n",
      "EleutherAI/pythia-1.4b\n",
      "EleutherAI/pythia-1.4b-deduped\n",
      "EleutherAI/pythia-12b\n",
      "EleutherAI/pythia-12b-deduped\n",
      "EleutherAI/pythia-14m\n",
      "EleutherAI/pythia-160m\n",
      "EleutherAI/pythia-160m-deduped\n",
      "EleutherAI/pythia-1b\n",
      "EleutherAI/pythia-1b-deduped\n",
      "EleutherAI/pythia-2.8b\n",
      "EleutherAI/pythia-2.8b-deduped\n",
      "EleutherAI/pythia-31m\n",
      "EleutherAI/pythia-410m\n",
      "EleutherAI/pythia-410m-deduped\n",
      "EleutherAI/pythia-6.9b\n",
      "EleutherAI/pythia-6.9b-deduped\n",
      "EleutherAI/pythia-70m\n",
      "EleutherAI/pythia-70m-deduped\n",
      "garage-bAInd/Camel-Platypus2-13B\n",
      "garage-bAInd/Camel-Platypus2-70B\n",
      "garage-bAInd/Platypus-30B\n",
      "garage-bAInd/Platypus2-13B\n",
      "garage-bAInd/Platypus2-70B\n",
      "garage-bAInd/Platypus2-70B-instruct\n",
      "garage-bAInd/Platypus2-7B\n",
      "garage-bAInd/Stable-Platypus2-13B\n",
      "google/codegemma-7b-it\n",
      "google/gemma-2-27b\n",
      "google/gemma-2-27b-it\n",
      "google/gemma-2-2b\n",
      "google/gemma-2-2b-it\n",
      "google/gemma-2-9b\n",
      "google/gemma-2-9b-it\n",
      "google/gemma-2b\n",
      "google/gemma-2b-it\n",
      "google/gemma-7b\n",
      "google/gemma-7b-it\n",
      "HuggingFaceTB/SmolLM2-1.7B\n",
      "HuggingFaceTB/SmolLM2-1.7B-Instruct\n",
      "HuggingFaceTB/SmolLM2-135M\n",
      "HuggingFaceTB/SmolLM2-135M-Instruct\n",
      "HuggingFaceTB/SmolLM2-360M\n",
      "HuggingFaceTB/SmolLM2-360M-Instruct\n",
      "keeeeenw/MicroLlama\n",
      "meta-llama/Llama-2-13b-chat-hf\n",
      "meta-llama/Llama-2-13b-hf\n",
      "meta-llama/Llama-2-70b-chat-hf\n",
      "meta-llama/Llama-2-70b-hf\n",
      "meta-llama/Llama-2-7b-chat-hf\n",
      "meta-llama/Llama-2-7b-hf\n",
      "meta-llama/Llama-3.2-1B\n",
      "meta-llama/Llama-3.2-1B-Instruct\n",
      "meta-llama/Llama-3.2-3B\n",
      "meta-llama/Llama-3.2-3B-Instruct\n",
      "meta-llama/Llama-3.3-70B-Instruct\n",
      "meta-llama/Meta-Llama-3-70B\n",
      "meta-llama/Meta-Llama-3-70B-Instruct\n",
      "meta-llama/Meta-Llama-3-8B\n",
      "meta-llama/Meta-Llama-3-8B-Instruct\n",
      "meta-llama/Meta-Llama-3.1-405B\n",
      "meta-llama/Meta-Llama-3.1-405B-Instruct\n",
      "meta-llama/Meta-Llama-3.1-70B\n",
      "meta-llama/Meta-Llama-3.1-70B-Instruct\n",
      "meta-llama/Meta-Llama-3.1-8B\n",
      "meta-llama/Meta-Llama-3.1-8B-Instruct\n",
      "microsoft/phi-1_5\n",
      "microsoft/phi-2\n",
      "microsoft/Phi-3-mini-128k-instruct\n",
      "microsoft/Phi-3-mini-4k-instruct\n",
      "microsoft/Phi-3.5-mini-instruct\n",
      "microsoft/phi-4\n",
      "mistralai/mathstral-7B-v0.1\n",
      "mistralai/Mistral-7B-Instruct-v0.1\n",
      "mistralai/Mistral-7B-Instruct-v0.2\n",
      "mistralai/Mistral-7B-Instruct-v0.3\n",
      "mistralai/Mistral-7B-v0.1\n",
      "mistralai/Mistral-7B-v0.3\n",
      "mistralai/Mistral-Large-Instruct-2407\n",
      "mistralai/Mistral-Large-Instruct-2411\n",
      "mistralai/Mixtral-8x22B-Instruct-v0.1\n",
      "mistralai/Mixtral-8x22B-v0.1\n",
      "mistralai/Mixtral-8x7B-Instruct-v0.1\n",
      "mistralai/Mixtral-8x7B-v0.1\n",
      "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\n",
      "openlm-research/open_llama_13b\n",
      "openlm-research/open_llama_3b\n",
      "openlm-research/open_llama_7b\n",
      "Qwen/Qwen2.5-0.5B\n",
      "Qwen/Qwen2.5-0.5B-Instruct\n",
      "Qwen/Qwen2.5-1.5B\n",
      "Qwen/Qwen2.5-1.5B-Instruct\n",
      "Qwen/Qwen2.5-14B\n",
      "Qwen/Qwen2.5-14B-Instruct\n",
      "Qwen/Qwen2.5-32B\n",
      "Qwen/Qwen2.5-32B-Instruct\n",
      "Qwen/Qwen2.5-3B\n",
      "Qwen/Qwen2.5-3B-Instruct\n",
      "Qwen/Qwen2.5-72B\n",
      "Qwen/Qwen2.5-72B-Instruct\n",
      "Qwen/Qwen2.5-7B\n",
      "Qwen/Qwen2.5-7B-Instruct\n",
      "Qwen/Qwen2.5-Coder-0.5B\n",
      "Qwen/Qwen2.5-Coder-0.5B-Instruct\n",
      "Qwen/Qwen2.5-Coder-1.5B\n",
      "Qwen/Qwen2.5-Coder-1.5B-Instruct\n",
      "Qwen/Qwen2.5-Coder-14B\n",
      "Qwen/Qwen2.5-Coder-14B-Instruct\n",
      "Qwen/Qwen2.5-Coder-32B\n",
      "Qwen/Qwen2.5-Coder-32B-Instruct\n",
      "Qwen/Qwen2.5-Coder-3B\n",
      "Qwen/Qwen2.5-Coder-3B-Instruct\n",
      "Qwen/Qwen2.5-Coder-7B\n",
      "Qwen/Qwen2.5-Coder-7B-Instruct\n",
      "Qwen/Qwen2.5-Math-1.5B\n",
      "Qwen/Qwen2.5-Math-1.5B-Instruct\n",
      "Qwen/Qwen2.5-Math-72B\n",
      "Qwen/Qwen2.5-Math-72B-Instruct\n",
      "Qwen/Qwen2.5-Math-7B\n",
      "Qwen/Qwen2.5-Math-7B-Instruct\n",
      "Qwen/QwQ-32B-Preview\n",
      "stabilityai/FreeWilly2\n",
      "stabilityai/stable-code-3b\n",
      "stabilityai/stablecode-completion-alpha-3b\n",
      "stabilityai/stablecode-completion-alpha-3b-4k\n",
      "stabilityai/stablecode-instruct-alpha-3b\n",
      "stabilityai/stablelm-3b-4e1t\n",
      "stabilityai/stablelm-base-alpha-3b\n",
      "stabilityai/stablelm-base-alpha-7b\n",
      "stabilityai/stablelm-tuned-alpha-3b\n",
      "stabilityai/stablelm-tuned-alpha-7b\n",
      "stabilityai/stablelm-zephyr-3b\n",
      "tiiuae/falcon-180B\n",
      "tiiuae/falcon-180B-chat\n",
      "tiiuae/falcon-40b\n",
      "tiiuae/falcon-40b-instruct\n",
      "tiiuae/falcon-7b\n",
      "tiiuae/falcon-7b-instruct\n",
      "tiiuae/Falcon3-10B-Base\n",
      "tiiuae/Falcon3-10B-Instruct\n",
      "tiiuae/Falcon3-1B-Base\n",
      "tiiuae/Falcon3-1B-Instruct\n",
      "tiiuae/Falcon3-3B-Base\n",
      "tiiuae/Falcon3-3B-Instruct\n",
      "tiiuae/Falcon3-7B-Base\n",
      "tiiuae/Falcon3-7B-Instruct\n",
      "TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\n",
      "togethercomputer/LLaMA-2-7B-32K\n",
      "Trelis/Llama-2-7b-chat-hf-function-calling-v2\n",
      "unsloth/Mistral-7B-v0.2\n"
     ]
    }
   ],
   "source": [
    "! litgpt download list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Downlaod LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting HF_HUB_ENABLE_HF_TRANSFER=1\n",
      "config.json: 100%|█████████████████████████████| 684/684 [00:00<00:00, 1.60MB/s]\n",
      "generation_config.json: 100%|██████████████████| 111/111 [00:00<00:00, 36.2kB/s]\n",
      "model.safetensors: 100%|██████████████████▉| 1.22G/1.22G [01:49<00:00, 11.1MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 1.84M/1.84M [00:00<00:00, 2.07MB/s]\n",
      "tokenizer.model: 100%|███████████████████████| 500k/500k [00:00<00:00, 10.6MB/s]\n",
      "tokenizer_config.json: 100%|███████████████████| 930/930 [00:00<00:00, 8.01MB/s]\n",
      "Converting checkpoint files to LitGPT format.\n",
      "{'checkpoint_dir': PosixPath('checkpoints/keeeeenw/MicroLlama'),\n",
      " 'debug_mode': False,\n",
      " 'dtype': None,\n",
      " 'model_name': None}\n",
      "Loading weights: model.safetensors: 100%|███████████████| 00:04<00:00, 24.14it/s\n",
      "Saving converted checkpoint to checkpoints/keeeeenw/MicroLlama\n"
     ]
    }
   ],
   "source": [
    "# ! cd M3_weightloading/trial_notebooks/intermediates\n",
    "! litgpt download keeeeenw/MicroLlama\n",
    "# ! cd ../../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharmilisrinivasan/miniconda3/envs/llm_from_scratch_py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from litgpt import LLM\n",
    "llm = LLM.load(\"intermediates/checkpoints/keeeeenw/MicroLlama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"what happens? It's just a fact of life. No matter how fame sees you, that's not to say you don't have strength and motivation for success. Most bumps will just be bigger and you'll find that\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.generate(\"Every effort moves you forward, then\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " all you need is people!\" The only woman didnt move saw her close her eyes. She was front and center.\n",
      "\"On to the next move, for sure. Real est féin that you like but I don't think that and your past i don't think that and my journey it's real d as am I.\"\n",
      "\"Sång ej manie (It means ' thee man chen that we ' Ukrain2)' by Millrain is about to come out. the tune will be forge.\"\n",
      "\"The To Ser To Ser You borrow from ' ' the folk song!' by David Saerdal makes unsure of my speech against Hitler.\n",
      "\"Load of atmosphere that it's good to see. ' Oz 5 s Ali Spo d.osimeibutė, ne et kut bra, t kilk bas luddóbaca mi lábbam? aur teos grammar I śva s, mi s"
     ]
    }
   ],
   "source": [
    "result = llm.generate(\"Every effort moves you forward, then\", stream=True, max_new_tokens=200)\n",
    "for generated_token in result:\n",
    "    print(generated_token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Terminal\n",
    "# cd M3_weightloading/trial_notebooks/intermediates\n",
    "# litgpt chat keeeeenw/MicroLlama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_from_scratch_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
