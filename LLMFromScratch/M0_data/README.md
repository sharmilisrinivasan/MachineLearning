# M0_data

This folder contains the data tokenisation helper functions and training dataset required for the "LLM From Scratch" project. The project aims to build a foundational understanding of how large language models (LLMs) like GPT are constructed and trained from scratch. It is designed for machine learning enthusiasts and researchers who want to explore the inner workings of LLMs. Below is an overview of the contents:

## Contents

- **Helpers**: Provides utility functions for data tokenisation and dataset creation.
- **ponniyinselvan.txt**: This text file contains excerpts from the Tamil historical novel "Ponniyin Selvan" by Kalki Krishnamurthy. It is intended to be used as a training dataset for our simple GPT model.

## Notes

- `Trial Notebooks`:
  - Contains trial and test codes for utilities in `helpers.py`.
  - Useful for debugging or recreating the end-to-end system step by step.
  - Helps in understanding each step in detail.
